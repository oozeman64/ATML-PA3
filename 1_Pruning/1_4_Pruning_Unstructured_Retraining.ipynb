{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import copy"
      ],
      "metadata": {
        "id": "npgd5LxV7Sg7"
      },
      "id": "npgd5LxV7Sg7",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_random_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    print(f\"Fixed random seed: {seed}\")\n",
        "\n",
        "fix_random_seed(42)\n",
        "\n",
        "# For deterministic DataLoader behavior\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qchj-B2e7S0r",
        "outputId": "4d7c1fde-5cb1-40d9-a645-5b034013be25"
      },
      "id": "qchj-B2e7S0r",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed random seed: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================================\n",
        "# Configuration\n",
        "# ==========================================================\n",
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std = [0.229, 0.224, 0.225]\n",
        "BATCH_SIZE = 128\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(42)\n",
        "\n",
        "# ==========================================================\n",
        "# Transforms\n",
        "# ==========================================================\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
        "])\n",
        "\n",
        "# ==========================================================\n",
        "# Datasets and Splits\n",
        "# ==========================================================\n",
        "# Load once (without transform)\n",
        "full_train = torchvision.datasets.CIFAR100(root='./data', train=True, download=True)\n",
        "full_test = torchvision.datasets.CIFAR100(root='./data', train=False, download=True)\n",
        "\n",
        "# Split indices using a fixed seed generator\n",
        "train_indices, val_indices = random_split(range(len(full_train)), [45000, 5000], generator=g)\n",
        "test_indices, small_test_indices = random_split(range(len(full_test)), [7500, 2500], generator=g)\n",
        "\n",
        "# Wrap each subset with its own dataset and transform\n",
        "train_dataset = Subset(\n",
        "    torchvision.datasets.CIFAR100(root='./data', train=True, transform=train_transform),\n",
        "    train_indices.indices\n",
        ")\n",
        "val_dataset = Subset(\n",
        "    torchvision.datasets.CIFAR100(root='./data', train=True, transform=test_transform),\n",
        "    val_indices.indices\n",
        ")\n",
        "test_dataset = Subset(\n",
        "    torchvision.datasets.CIFAR100(root='./data', train=False, transform=test_transform),\n",
        "    test_indices.indices\n",
        ")\n",
        "small_test_dataset = Subset(\n",
        "    torchvision.datasets.CIFAR100(root='./data', train=False, transform=test_transform),\n",
        "    small_test_indices.indices\n",
        ")\n",
        "\n",
        "print(\"Training set size:\", len(train_dataset))\n",
        "print(\"Validation set size:\", len(val_dataset))\n",
        "print(\"Test set size:\", len(test_dataset))\n",
        "print(\"Small test size:\", len(small_test_dataset))\n",
        "\n",
        "# ==========================================================\n",
        "# Dataloaders\n",
        "# ==========================================================\n",
        "def get_loader(dataset, shuffle):\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g\n",
        "    )\n",
        "\n",
        "train_loader = get_loader(train_dataset, shuffle=True)\n",
        "val_loader = get_loader(val_dataset, shuffle=False)\n",
        "test_loader = get_loader(test_dataset, shuffle=False)\n",
        "small_test_loader = get_loader(small_test_dataset, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsJVVw507TiR",
        "outputId": "213efc76-9a12-4e7b-f50c-c0902cf9f49b"
      },
      "id": "hsJVVw507TiR",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 45000\n",
            "Validation set size: 5000\n",
            "Test set size: 7500\n",
            "Small test size: 2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_weight_histograms(model, title):\n",
        "    # Collect (layer_name, weights) pairs\n",
        "    layer_weights = []\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, (torch.nn.Conv2d, torch.nn.Linear)):\n",
        "            layer_weights.append((name, module.weight.detach().cpu().numpy().flatten()))\n",
        "\n",
        "    # Plot histograms\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    for i, (name, w) in enumerate(layer_weights[:11]):  # limit to first 11 for readability\n",
        "        plt.subplot(5, 6, i + 1)\n",
        "        plt.hist(w, bins=40, color='blue', alpha=0.7)\n",
        "        plt.title(name, fontsize=9)  # <-- actual layer name\n",
        "        plt.tight_layout()\n",
        "    plt.suptitle(title, y=1.02)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "RrXDoiko7UkA"
      },
      "id": "RrXDoiko7UkA",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_model_sparsity(model):\n",
        "    total_params = 0\n",
        "    zero_params = 0\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param is not None:\n",
        "            numel = param.numel()\n",
        "            total_params += numel\n",
        "            zero_params += torch.sum(param == 0).item()\n",
        "\n",
        "    sparsity = 100.0 * zero_params / total_params if total_params > 0 else 0.0\n",
        "\n",
        "    print(f\"Total Parameters: {total_params:,}\")\n",
        "    print(f\"Zero (Pruned) Parameters: {zero_params:,}\")\n",
        "    print(f\"Sparsity: {sparsity:.2f}%\")"
      ],
      "metadata": {
        "id": "V6_lKcQJ7VoE"
      },
      "id": "V6_lKcQJ7VoE",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg11_pruned = models.vgg11(weights=models.VGG11_Weights.IMAGENET1K_V1)\n",
        "vgg11_pruned.classifier[6] = torch.nn.Linear(4096, 100)\n",
        "vgg11_pruned.classifier[5] = torch.nn.Dropout(p=0.5) # Dropout\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
        "vgg11_pruned.load_state_dict(torch.load('models/vgg11_cifar100_pruned_unstructured.pt', weights_only=True, map_location=device))\n",
        "vgg11_pruned.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDW6vZ-g7Wlq",
        "outputId": "c94cf9ae-7305-4d67-8377-771963db9db1"
      },
      "id": "wDW6vZ-g7Wlq",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (14): ReLU(inplace=True)\n",
              "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            preds = model(images)\n",
        "            preds = torch.argmax(preds, dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "5yc6d3A17Xoh"
      },
      "id": "5yc6d3A17Xoh",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sparsity of pruned model\n",
        "print(\"Unstructured Pruning before Retraining\")\n",
        "print_model_sparsity(vgg11_pruned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJrxg19p7bVq",
        "outputId": "806f0760-4c08-42b2-f92f-15498a775813"
      },
      "id": "yJrxg19p7bVq",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unstructured Pruning before Retraining\n",
            "Total Parameters: 129,176,036\n",
            "Zero (Pruned) Parameters: 90,415,675\n",
            "Sparsity: 69.99%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = evaluate(vgg11_pruned, test_loader, device)\n",
        "print(f\"Unstructured Pruning Accuracy Before Retraining: {acc:.2f}%\")\n",
        "\n",
        "acc = evaluate(vgg11_pruned, small_test_loader, device)\n",
        "print(f\"Unstructured Pruning Accuracy Before Retraining (Small): {acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExnwrTEt7c1O",
        "outputId": "e1b22f29-24ce-4629-ccca-d2da6e46960e"
      },
      "id": "ExnwrTEt7c1O",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unstructured Pruning Accuracy Before Retraining: 72.73%\n",
            "Unstructured Pruning Accuracy Before Retraining (Small): 71.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for inputs, labels in loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / total\n",
        "    accuracy = 100. * correct / total\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "XLqnE-F47drd"
      },
      "id": "XLqnE-F47drd",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_lr = 0.04\n",
        "weight_decay = 5e-4\n",
        "num_epochs = 5\n",
        "optim = torch.optim.SGD(\n",
        "    vgg11_pruned.parameters(),\n",
        "    lr=base_lr,\n",
        "    momentum=0.9,\n",
        "    weight_decay=weight_decay\n",
        ")\n",
        "scheduler = CosineAnnealingLR(optim, T_max=num_epochs, eta_min=1e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ef86y5G47etr"
      },
      "id": "ef86y5G47etr",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val = 0\n",
        "best_retrained = copy.deepcopy(vgg11_pruned)\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train_epoch(vgg11_pruned, train_loader, criterion, optim, device)\n",
        "    scheduler.step()\n",
        "    val_acc = evaluate(vgg11_pruned, val_loader, device)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
        "    if val_acc > best_val:\n",
        "      best_retrained = copy.deepcopy(vgg11_pruned)\n",
        "      best_val = val_acc\n",
        "      torch.save(vgg11_pruned.state_dict(), \"vgg11_cifar100_pruned_unstructured_finetuned.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qyqlv-NV7fnZ",
        "outputId": "e695001f-7493-4955-e460-baf5c19d29fd"
      },
      "id": "Qyqlv-NV7fnZ",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Loss: 1.3131 | Train Acc: 62.96% | Val Acc: 57.08%\n",
            "Epoch 2/5 | Loss: 1.1208 | Train Acc: 68.10% | Val Acc: 62.36%\n",
            "Epoch 3/5 | Loss: 0.7556 | Train Acc: 77.70% | Val Acc: 67.04%\n",
            "Epoch 4/5 | Loss: 0.4037 | Train Acc: 87.75% | Val Acc: 69.44%\n",
            "Epoch 5/5 | Loss: 0.2013 | Train Acc: 93.74% | Val Acc: 72.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unstructured Pruning after Retraining\")\n",
        "print_model_sparsity(best_retrained)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qoIQM5q7gzf",
        "outputId": "c46180b9-fe54-40c8-bd18-6bfb1623402d"
      },
      "id": "-qoIQM5q7gzf",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unstructured Pruning after Retraining\n",
            "Total Parameters: 129,176,036\n",
            "Zero (Pruned) Parameters: 110,576\n",
            "Sparsity: 0.09%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = evaluate(best_retrained, test_loader, device)\n",
        "print(f\"Unstructured Pruning Accuracy After Retraining: {acc:.2f}%\")\n",
        "\n",
        "acc = evaluate(best_retrained, small_test_loader, device)\n",
        "print(f\"Unstructured Pruning Accuracy After Retraining (Small): {acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB89iaCN7hpl",
        "outputId": "e4800d3b-2902-489f-c1b1-c9319603bfb3"
      },
      "id": "AB89iaCN7hpl",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unstructured Pruning Accuracy After Retraining: 72.64%\n",
            "Unstructured Pruning Accuracy After Retraining (Small): 72.32%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For simplicity, use the same pruning settings as applied previously\n",
        "\n",
        "base_acc = 71.44\n",
        "\n",
        "with open('models/sensitivity_dict_unstructured.pkl', 'rb') as f:\n",
        "    sensitivity_dict = pickle.load(f)\n",
        "\n",
        "prune_amts = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "desired_prune = 0.7\n",
        "max_layer_prune = 0.9\n",
        "min_layer_prune = 0.1  # don't prune below 10% to avoid imbalance\n",
        "\n",
        "# 1) gather layers and parameter counts\n",
        "layer_param_count = {}\n",
        "conv_order = []  # track order for depth weighting\n",
        "for name, module in best_retrained.named_modules():\n",
        "    if isinstance(module, (torch.nn.Conv2d, torch.nn.Linear)):\n",
        "        nparams = sum(p.numel() for p in module.parameters())\n",
        "        layer_param_count[name] = nparams\n",
        "        conv_order.append(name)\n",
        "\n",
        "total_params = sum(layer_param_count.values())\n",
        "total_remove_target = int(desired_prune * total_params)\n",
        "\n",
        "# 2) compute robustness R_l (lower R = more sensitive)\n",
        "R = {}\n",
        "for name in layer_param_count:\n",
        "    accs = []\n",
        "    for p in prune_amts:\n",
        "        acc = sensitivity_dict.get((name, p))\n",
        "        if acc is not None:\n",
        "            accs.append(acc)\n",
        "    if not accs or base_acc == 0:\n",
        "        R[name] = 1.0\n",
        "    else:\n",
        "        R[name] = (sum(accs) / len(accs)) / base_acc\n",
        "\n",
        "print(\"Robustness:\")\n",
        "print(R)\n",
        "\n",
        "# 3) convert robustness to sensitivity (S = 1 / R) with clamping\n",
        "S = {n: 1.0 / max(R[n], 1e-6) for n in R}\n",
        "\n",
        "# 4) apply depth weighting (deeper layers get more pruning)\n",
        "depth_weights = {}\n",
        "for i, name in enumerate(conv_order):\n",
        "    depth_weights[name] = 1.0 + (i / len(conv_order))  # linear increase by depth\n",
        "\n",
        "# 5) combine into pruning importance score\n",
        "# lower S -> less pruning; higher depth -> more pruning\n",
        "score = {n: depth_weights[n] / S[n] for n in layer_param_count}\n",
        "\n",
        "# 6) allocate pruning proportionally to score * param_count\n",
        "denom = sum(score[n] * layer_param_count[n] for n in score)\n",
        "remove_alloc = {}\n",
        "for name in score:\n",
        "    remove_alloc[name] = total_remove_target * (score[name] * layer_param_count[name]) / denom\n",
        "\n",
        "# 7) compute final per-layer pruning %\n",
        "prune_pct = {}\n",
        "for name in remove_alloc:\n",
        "    pct = remove_alloc[name] / layer_param_count[name]\n",
        "    pct = min(max(pct, min_layer_prune), max_layer_prune)\n",
        "    prune_pct[name] = pct\n",
        "\n",
        "print(\"\\nAdjusted Prune Percentages:\")\n",
        "for k, v in prune_pct.items():\n",
        "    print(f\"{k}: {v*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFaHVhzl71ov",
        "outputId": "a51f627b-17cf-4df7-9976-64a9824899b4"
      },
      "id": "ZFaHVhzl71ov",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Robustness:\n",
            "{'features.0': 0.8597113350752769, 'features.3': 1.016548463356974, 'features.6': 1.0189747418190866, 'features.8': 1.0093940525071545, 'features.11': 1.009269627970636, 'features.13': 1.0070921985815602, 'features.16': 0.9934677118327734, 'features.18': 0.995458504417071, 'classifier.0': 1.0212143834764218, 'classifier.3': 1.0217742938907552, 'classifier.6': 1.022769690182904}\n",
            "\n",
            "Adjusted Prune Percentages:\n",
            "features.0: 34.25%\n",
            "features.3: 44.18%\n",
            "features.6: 47.97%\n",
            "features.8: 51.18%\n",
            "features.11: 54.83%\n",
            "features.13: 58.35%\n",
            "features.16: 61.16%\n",
            "features.18: 64.89%\n",
            "classifier.0: 70.27%\n",
            "classifier.3: 74.01%\n",
            "classifier.6: 77.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_layer_unstructured_L2(module, amount=0.3):\n",
        "    # Only prune Conv2d or Linear layers\n",
        "    if not isinstance(module, (torch.nn.Conv2d, torch.nn.Linear)):\n",
        "        return 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Flatten weights\n",
        "        weights = module.weight.data.view(-1)\n",
        "        num_params = weights.numel()\n",
        "        num_prune = int(amount * num_params)\n",
        "\n",
        "        if num_prune == 0:\n",
        "            return 0\n",
        "\n",
        "        # Compute L2 magnitudes (since weights are scalars, this is just abs)\n",
        "        magnitudes = weights.abs()\n",
        "\n",
        "        # Get threshold\n",
        "        threshold = torch.topk(magnitudes, num_prune, largest=False).values.max()\n",
        "\n",
        "        # Zero out the smallest weights\n",
        "        mask = magnitudes > threshold\n",
        "        module.weight.data.view(-1)[~mask] = 0\n",
        "\n",
        "        return num_prune"
      ],
      "metadata": {
        "id": "2kSGPZCV8CLe"
      },
      "id": "2kSGPZCV8CLe",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) apply pruning (use a copy of the model)\n",
        "vgg_pruned_finetuned = copy.deepcopy(best_retrained)\n",
        "\n",
        "for name, module in vgg_pruned_finetuned.named_modules():\n",
        "    if name in prune_pct:\n",
        "        p = prune_pct[name]\n",
        "        if p <= 0:\n",
        "            continue\n",
        "        if isinstance(module, (torch.nn.Conv2d, torch.nn.Linear)):\n",
        "            try:\n",
        "                prune_layer_unstructured_L2(module, amount=p)\n",
        "            except Exception as e:\n",
        "                print(f\"Cannot prune layer {name}: {e}\")\n"
      ],
      "metadata": {
        "id": "iZVN5Dgt8DHV"
      },
      "id": "iZVN5Dgt8DHV",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unstructured Pruning after Finetuning and Pruning Again\")\n",
        "print_model_sparsity(vgg_pruned_finetuned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHNW2tck8GXv",
        "outputId": "58ffbcff-6456-4acd-b707-e1f6fb4361cc"
      },
      "id": "VHNW2tck8GXv",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unstructured Pruning after Finetuning and Pruning Again\n",
            "Total Parameters: 129,176,036\n",
            "Zero (Pruned) Parameters: 90,415,678\n",
            "Sparsity: 69.99%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = evaluate(vgg_pruned_finetuned, test_loader, device)\n",
        "print(f\"Unstructured Pruning after Finetuning and Pruning Again: {acc:.2f}%\")\n",
        "\n",
        "acc = evaluate(vgg_pruned_finetuned, small_test_loader, device)\n",
        "print(f\"Unstructured Pruning after Finetuning and Pruning Again (Small): {acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tUOPOAn8H1k",
        "outputId": "080ae535-b354-474f-e8ac-78aa7c1c1daa"
      },
      "id": "3tUOPOAn8H1k",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unstructured Pruning after Finetuning and Pruning Again: 72.28%\n",
            "Unstructured Pruning after Finetuning and Pruning Again (Small): 71.72%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(vgg_pruned_finetuned.state_dict(), \"vgg11_cifar100_pruned_unstructured_finetuned_pruned.pt\")"
      ],
      "metadata": {
        "id": "rxrVo9918JOK"
      },
      "id": "rxrVo9918JOK",
      "execution_count": 58,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}