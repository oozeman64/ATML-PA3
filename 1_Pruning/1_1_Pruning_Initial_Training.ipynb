{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "12dba74f",
      "metadata": {
        "id": "12dba74f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "73792f66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73792f66",
        "outputId": "f4bbe0b6-3927-4f09-8788-a2bfc0b74523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed random seed: 42\n"
          ]
        }
      ],
      "source": [
        "def fix_random_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    print(f\"Fixed random seed: {seed}\")\n",
        "\n",
        "fix_random_seed(42)\n",
        "\n",
        "# For deterministic DataLoader behavior\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg11 = models.vgg11(weights=models.VGG11_Weights.IMAGENET1K_V1)\n",
        "vgg11.classifier[6] = torch.nn.Linear(4096, 100)\n",
        "vgg11.classifier[5] = torch.nn.Dropout(p=0.5) # Dropout\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
        "vgg11 = vgg11.to(device)\n",
        "\n",
        "base_lr = 0.04\n",
        "weight_decay = 5e-4\n",
        "num_epochs = 10\n",
        "optim = torch.optim.SGD(\n",
        "    vgg11.parameters(),\n",
        "    lr=base_lr,\n",
        "    momentum=0.9,\n",
        "    weight_decay=weight_decay\n",
        ")\n",
        "\n",
        "scheduler = CosineAnnealingLR(optim, T_max=num_epochs, eta_min=1e-5)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "doksXZ0XoCCN"
      },
      "id": "doksXZ0XoCCN",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6e5dd655",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e5dd655",
        "outputId": "b91bf8a4-f39a-4264-fa3e-4dd3ec3aeebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 45000\n",
            "Validation set size: 5000\n",
            "Test set size: 7500\n",
            "Small test size: 2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ==========================================================\n",
        "# Configuration\n",
        "# ==========================================================\n",
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std = [0.229, 0.224, 0.225]\n",
        "BATCH_SIZE = 128\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(42)\n",
        "\n",
        "# ==========================================================\n",
        "# Transforms\n",
        "# ==========================================================\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
        "])\n",
        "\n",
        "# ==========================================================\n",
        "# Datasets and Splits\n",
        "# ==========================================================\n",
        "# Load once (without transform)\n",
        "full_train = torchvision.datasets.CIFAR100(root='./data', train=True, download=True)\n",
        "full_test = torchvision.datasets.CIFAR100(root='./data', train=False, download=True)\n",
        "\n",
        "# Split indices using a fixed seed generator\n",
        "train_indices, val_indices = random_split(range(len(full_train)), [45000, 5000], generator=g)\n",
        "test_indices, small_test_indices = random_split(range(len(full_test)), [7500, 2500], generator=g)\n",
        "\n",
        "# Wrap each subset with its own dataset and transform\n",
        "train_dataset = Subset(\n",
        "    torchvision.datasets.CIFAR100(root='./data', train=True, transform=train_transform),\n",
        "    train_indices.indices\n",
        ")\n",
        "val_dataset = Subset(\n",
        "    torchvision.datasets.CIFAR100(root='./data', train=True, transform=test_transform),\n",
        "    val_indices.indices\n",
        ")\n",
        "test_dataset = Subset(\n",
        "    torchvision.datasets.CIFAR100(root='./data', train=False, transform=test_transform),\n",
        "    test_indices.indices\n",
        ")\n",
        "small_test_dataset = Subset(\n",
        "    torchvision.datasets.CIFAR100(root='./data', train=False, transform=test_transform),\n",
        "    small_test_indices.indices\n",
        ")\n",
        "\n",
        "print(\"Training set size:\", len(train_dataset))\n",
        "print(\"Validation set size:\", len(val_dataset))\n",
        "print(\"Test set size:\", len(test_dataset))\n",
        "print(\"Small test size:\", len(small_test_dataset))\n",
        "\n",
        "# ==========================================================\n",
        "# Dataloaders\n",
        "# ==========================================================\n",
        "def get_loader(dataset, shuffle):\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g\n",
        "    )\n",
        "\n",
        "train_loader = get_loader(train_dataset, shuffle=True)\n",
        "val_loader = get_loader(val_dataset, shuffle=False)\n",
        "test_loader = get_loader(test_dataset, shuffle=False)\n",
        "small_test_loader = get_loader(small_test_dataset, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "95851c20",
      "metadata": {
        "id": "95851c20"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for inputs, labels in loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / total\n",
        "    accuracy = 100. * correct / total\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b292161c",
      "metadata": {
        "id": "b292161c"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            preds = model(images)\n",
        "            preds = torch.argmax(preds, dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2b85fd2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b85fd2c",
        "outputId": "f1137897-c5c0-4cc1-9186-6f7550181d74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 3.2270 | Train Acc: 22.32% | Val Acc: 38.48%\n",
            "Epoch 2/10 | Loss: 2.0479 | Train Acc: 45.09% | Val Acc: 51.26%\n",
            "Epoch 3/10 | Loss: 1.6099 | Train Acc: 55.44% | Val Acc: 55.72%\n",
            "Epoch 4/10 | Loss: 1.3100 | Train Acc: 62.86% | Val Acc: 60.46%\n",
            "Epoch 5/10 | Loss: 1.0313 | Train Acc: 70.12% | Val Acc: 65.68%\n",
            "Epoch 6/10 | Loss: 0.7500 | Train Acc: 77.66% | Val Acc: 66.40%\n",
            "Epoch 7/10 | Loss: 0.5152 | Train Acc: 84.09% | Val Acc: 70.04%\n",
            "Epoch 8/10 | Loss: 0.3232 | Train Acc: 89.88% | Val Acc: 72.34%\n",
            "Epoch 9/10 | Loss: 0.2028 | Train Acc: 93.57% | Val Acc: 73.26%\n",
            "Epoch 10/10 | Loss: 0.1438 | Train Acc: 95.48% | Val Acc: 73.86%\n"
          ]
        }
      ],
      "source": [
        "best_val = 0\n",
        "best_vgg11 = copy.deepcopy(vgg11)\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train_epoch(vgg11, train_loader, criterion, optim, device)\n",
        "    scheduler.step()\n",
        "    val_acc = evaluate(vgg11, val_loader, device)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
        "    if val_acc > best_val:\n",
        "      best_vgg11 = copy.deepcopy(vgg11)\n",
        "      best_val = val_acc\n",
        "      torch.save(vgg11.state_dict(), \"vgg11_cifar100_baseline_6e.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7de7a58f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7de7a58f",
        "outputId": "1679a79c-7166-4730-814f-0c60c4033c52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 74.33%\n"
          ]
        }
      ],
      "source": [
        "acc = evaluate(best_vgg11, test_loader, device)\n",
        "print(f\"Accuracy: {acc:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}