{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17631834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import torchao\n",
    "from copy import deepcopy\n",
    "import time\n",
    "from torchao.quantization import (\n",
    "    quantize_,\n",
    "    Int8WeightOnlyConfig,\n",
    "    Int4WeightOnlyConfig\n",
    ")\n",
    "from torchao.quantization.qat import QATConfig\n",
    "from torchao.dtypes import Int4CPULayout\n",
    "from torch import nn\n",
    "import torchao\n",
    "\n",
    "from torchao.quantization import Int8DynamicActivationInt8WeightConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f0ea3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8cc49d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "  model.to(device)\n",
    "  model.train()\n",
    "  running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "  for inputs, labels in tqdm(loader):\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(inputs)              # forward pass\n",
    "    loss = criterion(logits, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "    _, predicted = torch.max(logits.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "  avg_loss = running_loss / total\n",
    "  accuracy = 100. * correct / total\n",
    "  return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, device):\n",
    "  model.eval()\n",
    "  model.to(device)\n",
    "\n",
    "  correct = 0\n",
    "  total = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      outputs = model(images)\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "\n",
    "  accuracy = 100 * correct / total\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b019b06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed random seed: 42\n"
     ]
    }
   ],
   "source": [
    "def fix_random_seed(seed=42):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = False\n",
    "  print(f\"Fixed random seed: {seed}\")\n",
    "\n",
    "fix_random_seed(42)\n",
    "\n",
    "# For deterministic DataLoader behavior\n",
    "def seed_worker(worker_id):\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)\n",
    "\n",
    "def get_model_size(model, path=\"/tmp/temp_model.pt\"):\n",
    "  \"\"\"\n",
    "  Save a PyTorch model temporarily and return its size in MB.\n",
    "\n",
    "  Args:\n",
    "      model: PyTorch model (nn.Module)\n",
    "      path: Temporary file path to save the model\n",
    "\n",
    "  Returns:\n",
    "      Size of the model in MB (float)\n",
    "  \"\"\"\n",
    "  torch.save(model, path)\n",
    "  size_mb = os.path.getsize(path) / 1024 / 1024\n",
    "  return size_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b8edf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 45000\n",
      "Validation set size: 5000\n",
      "Test set size: 10000\n"
     ]
    }
   ],
   "source": [
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "])\n",
    "\n",
    "full_train = torchvision.datasets.CIFAR100(root='./data', train=True, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True)\n",
    "train_subset, val_subset = random_split(full_train, [45000, 5000], generator=g)\n",
    "\n",
    "train_subset.dataset.transform = train_transform\n",
    "val_subset.dataset.transform = test_transform\n",
    "test_dataset.transform = test_transform\n",
    "\n",
    "print(\"Training set size:\", len(train_subset))\n",
    "print(\"Validation set size:\", len(val_subset))\n",
    "print(\"Test set size:\", len(test_dataset))\n",
    "\n",
    "def get_loader(dataset, shuffle):\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g\n",
    "    )\n",
    "\n",
    "train_loader = get_loader(train_subset, shuffle=True)\n",
    "val_loader = get_loader(val_subset, shuffle=False)\n",
    "test_loader = get_loader(test_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3aeca4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = models.vgg11(weights=models.VGG11_Weights.IMAGENET1K_V1)\n",
    "model_base.classifier[6] = torch.nn.Linear(4096, 100)\n",
    "model_base.classifier[5] = torch.nn.Dropout(p=0.5) # Dropout\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "model_base = model_base.to(device)\n",
    "\n",
    "# base_lr = 0.04\n",
    "# weight_decay = 5e-4\n",
    "# num_epochs = 6\n",
    "# optim = torch.optim.SGD(\n",
    "#     model_base.parameters(),\n",
    "#     lr=base_lr,\n",
    "#     momentum=0.9,\n",
    "#     weight_decay=weight_decay\n",
    "# )\n",
    "\n",
    "# scheduler = CosineAnnealingLR(optim, T_max=num_epochs, eta_min=1e-5)\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e4657f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = deepcopy(model_base)\n",
    "model.load_state_dict(torch.load(\"vgg11_cifar100_baseline_5e.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dde9294c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized classifier[0] to INT8\n",
      "Quantized classifier[3] to INT8\n",
      "Kept classifier[6] as FP32\n",
      "Kept all conv layers as FP32\n",
      "features.0: FP32 (conv layer) - torch.float32\n",
      "features.3: FP32 (conv layer) - torch.float32\n",
      "features.6: FP32 (conv layer) - torch.float32\n",
      "features.8: FP32 (conv layer) - torch.float32\n",
      "features.11: FP32 (conv layer) - torch.float32\n",
      "features.13: FP32 (conv layer) - torch.float32\n",
      "features.16: FP32 (conv layer) - torch.float32\n",
      "features.18: FP32 (conv layer) - torch.float32\n",
      "classifier.0: INT8 (quantized) - torch.int8\n",
      "classifier.3: INT8 (quantized) - torch.int8\n",
      "classifier.6: FP32 (not quantized) - torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "100%|██████████| 79/79 [01:03<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Accuracy = 67.77, Inference Time = 63.709638833999634, Size = 150.88 MB\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Manually quantize specific layers\n",
    "def apply_mixed_precision_simple(model):\n",
    "    \"\"\"\n",
    "    Apply INT8 to specific linear layers only\n",
    "    \"\"\"\n",
    "    # Quantize classifier[0] (first linear layer)\n",
    "    temp_0 = nn.Sequential(model.classifier[0])\n",
    "    quantize_(temp_0, Int8WeightOnlyConfig())\n",
    "    model.classifier[0] = temp_0[0]\n",
    "    print(\"Quantized classifier[0] to INT8\")\n",
    "    \n",
    "    # Quantize classifier[3] (second linear layer)\n",
    "    temp_3 = nn.Sequential(model.classifier[3])\n",
    "    quantize_(temp_3, Int8WeightOnlyConfig())\n",
    "    model.classifier[3] = temp_3[0]\n",
    "    print(\"Quantized classifier[3] to INT8\")\n",
    "    \n",
    "    # Keep classifier[6] as FP32 (don't quantize)\n",
    "    print(\"Kept classifier[6] as FP32\")\n",
    "    \n",
    "    # Keep all conv layers as FP32 (don't quantize features)\n",
    "    print(\"Kept all conv layers as FP32\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_mixed = deepcopy(model)\n",
    "model_mixed.to(device)\n",
    "model_mixed = apply_mixed_precision_simple(model_mixed)\n",
    "# model_mixed = torch.compile(model_mixed, mode='max-autotune')\n",
    "\n",
    "for name, layer in model_mixed.named_modules():\n",
    "    if isinstance(layer, torch.nn.Linear):\n",
    "        # Check if weight has tensor_impl (quantized) or not (FP32)\n",
    "        if hasattr(layer.weight, 'tensor_impl'):\n",
    "            print(f\"{name}: INT8 (quantized) - {layer.weight.tensor_impl.dtype}\")\n",
    "        else:\n",
    "            print(f\"{name}: FP32 (not quantized) - {layer.weight.dtype}\")\n",
    "    elif isinstance(layer, torch.nn.Conv2d):\n",
    "        print(f\"{name}: FP32 (conv layer) - {layer.weight.dtype}\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model_mixed(inputs)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "end_time = time.time()\n",
    "inf_time = end_time - start_time\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "model_size = get_model_size(model_mixed, \"vgg11_mixed.pt\")\n",
    "print(f\"\\n Test Accuracy = {test_acc:.2f}, Inference Time = {inf_time}, Size = {model_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8fa4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting activation variance per layer...\n",
      "Applying adaptive FP32/FP16/INT8 quantization (fixed replacer)...\n",
      "Adaptive thresholds (percentiles 30/70): low=3.450456, high=10.158555\n",
      "features.0: kept Conv2d FP32\n",
      "features.3: kept Conv2d FP32\n",
      "features.6: kept Conv2d FP32\n",
      "features.8: kept Conv2d FP32\n",
      "features.11: kept Conv2d FP32\n",
      "features.13: kept Conv2d FP32\n",
      "features.16: kept Conv2d FP32\n",
      "features.18: kept Conv2d FP32\n",
      "classifier.0: -> FP16 (var=3.450456 between 3.450456 and 10.158555)\n",
      "classifier.3: -> INT8 (var=0.794579 < 3.450456)\n",
      "classifier.6: keep FP32 (var=25.867520 >= 10.158555)\n",
      "\n",
      "Layer weight dtypes (first 200 layers):\n",
      "features.0                               : weight dtype=torch.float32  module_type=Conv2d\n",
      "features.3                               : weight dtype=torch.float32  module_type=Conv2d\n",
      "features.6                               : weight dtype=torch.float32  module_type=Conv2d\n",
      "features.8                               : weight dtype=torch.float32  module_type=Conv2d\n",
      "features.11                              : weight dtype=torch.float32  module_type=Conv2d\n",
      "features.13                              : weight dtype=torch.float32  module_type=Conv2d\n",
      "features.16                              : weight dtype=torch.float32  module_type=Conv2d\n",
      "features.18                              : weight dtype=torch.float32  module_type=Conv2d\n",
      "classifier.0.module                      : weight dtype=torch.float16  module_type=Linear\n",
      "classifier.3                             : weight dtype=torch.float32  module_type=Linear\n",
      "classifier.6                             : weight dtype=torch.float32  module_type=Linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [05:23<00:00,  4.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adaptive Mixed Precision (FP32/FP16/INT8): Accuracy = 71.01%, Inference Time = 323.41s, Size = 248.82 MB\n"
     ]
    }
   ],
   "source": [
    "def compute_activation_variance(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Compute per-layer activation variance using forward hooks.\n",
    "    \"\"\"\n",
    "    activation_variances = {}\n",
    "\n",
    "    def hook_fn(name):\n",
    "        def hook(module, input, output):\n",
    "            # Compute variance of activations (flattened)\n",
    "            with torch.no_grad():\n",
    "                var = output.detach().float().var().item()\n",
    "                if name in activation_variances:\n",
    "                    activation_variances[name].append(var)\n",
    "                else:\n",
    "                    activation_variances[name] = [var]\n",
    "        return hook\n",
    "\n",
    "    hooks = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            hooks.append(module.register_forward_hook(hook_fn(name)))\n",
    "\n",
    "    # Run a few batches through to collect stats\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, _) in enumerate(data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            model(inputs)\n",
    "            if i >= 5:  # use a few batches for estimation\n",
    "                break\n",
    "\n",
    "    # Average the variances for each layer\n",
    "    for name in activation_variances:\n",
    "        activation_variances[name] = sum(activation_variances[name]) / len(activation_variances[name])\n",
    "\n",
    "    # Remove hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    return activation_variances\n",
    "\n",
    "def get_module_and_parent(root: nn.Module, dotted_name: str):\n",
    "    \"\"\"\n",
    "    Return (parent_module, child_name, child_module)\n",
    "    For dotted_name \"a.b.c\" returns (module_at_a.b, \"c\", module_at_a.b.c)\n",
    "    If dotted_name has no dot, parent is root and child_name is dotted_name.\n",
    "    \"\"\"\n",
    "    parts = dotted_name.split('.')\n",
    "    if len(parts) == 1:\n",
    "        parent = root\n",
    "        child_name = parts[0]\n",
    "        child = parent._modules.get(child_name, None)\n",
    "        return parent, child_name, child\n",
    "\n",
    "    parent = root\n",
    "    for p in parts[:-1]:\n",
    "        parent = parent._modules.get(p)\n",
    "        if parent is None:\n",
    "            return None, None, None\n",
    "    child_name = parts[-1]\n",
    "    child = parent._modules.get(child_name, None)\n",
    "    return parent, child_name, child\n",
    "\n",
    "def set_submodule_by_name(root: nn.Module, dotted_name: str, new_module: nn.Module, device=None):\n",
    "    \"\"\"\n",
    "    Replace submodule located at dotted_name with new_module.\n",
    "    Moves new_module to device if provided.\n",
    "    \"\"\"\n",
    "    parent, child_name, child = get_module_and_parent(root, dotted_name)\n",
    "    if parent is None:\n",
    "        raise KeyError(f\"Parent for '{dotted_name}' not found.\")\n",
    "    if device is None:\n",
    "        for p in parent.parameters(recurse=False):\n",
    "            device = p.device\n",
    "            break\n",
    "    if device is not None:\n",
    "        new_module.to(device)\n",
    "    parent._modules[child_name] = new_module\n",
    "\n",
    "class FP16Wrapper(nn.Module):\n",
    "    \"\"\"Wrap a module to run internal computation in float16 while exposing float32 interface.\"\"\"\n",
    "    def __init__(self, module: nn.Module):\n",
    "        super().__init__()\n",
    "        self.module = deepcopy(module).half()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dtype != torch.float16:\n",
    "            x_h = x.to(torch.float16)\n",
    "        else:\n",
    "            x_h = x\n",
    "        out_h = self.module(x_h)\n",
    "        if out_h.dtype != torch.float32:\n",
    "            return out_h.to(torch.float32)\n",
    "        return out_h\n",
    "\n",
    "def apply_adaptive_mixed_precision_fixed(model: nn.Module, act_variances: dict,\n",
    "                                         device=None, keep_conv_as_fp32=True,\n",
    "                                         low_pct=30, high_pct=70):\n",
    "    \"\"\"\n",
    "    Adaptive precision selection with correct submodule replacement.\n",
    "    - low_pct / high_pct define percentile thresholds.\n",
    "    - keep_conv_as_fp32: if False, convs will be considered for FP16/INT8 as well.\n",
    "    \"\"\"\n",
    "    vars_list = list(act_variances.values()) if len(act_variances) > 0 else [0.0]\n",
    "    low_var_threshold = float(np.percentile(vars_list, low_pct))\n",
    "    high_var_threshold = float(np.percentile(vars_list, high_pct))\n",
    "\n",
    "    print(f\"Adaptive thresholds (percentiles {low_pct}/{high_pct}):\"\n",
    "          f\" low={low_var_threshold:.6f}, high={high_var_threshold:.6f}\")\n",
    "\n",
    "    named_modules = list(model.named_modules())\n",
    "\n",
    "    for name, module in named_modules:\n",
    "        if name == '':\n",
    "            continue\n",
    "\n",
    "        if isinstance(module, nn.Linear) or (not keep_conv_as_fp32 and isinstance(module, nn.Conv2d)):\n",
    "            var = float(act_variances.get(name, 0.0))\n",
    "            if var < low_var_threshold:\n",
    "                q_temp = deepcopy(module)\n",
    "                q_temp_seq = nn.Sequential(q_temp)\n",
    "                quantize_(q_temp_seq, Int8WeightOnlyConfig())\n",
    "                new_mod = q_temp_seq[0]\n",
    "                print(f\"{name}: -> INT8 (var={var:.6f} < {low_var_threshold:.6f})\")\n",
    "\n",
    "            elif var < high_var_threshold:\n",
    "                new_mod = FP16Wrapper(module)\n",
    "                print(f\"{name}: -> FP16 (var={var:.6f} between {low_var_threshold:.6f} and {high_var_threshold:.6f})\")\n",
    "\n",
    "            else:\n",
    "                new_mod = deepcopy(module).float()\n",
    "                print(f\"{name}: keep FP32 (var={var:.6f} >= {high_var_threshold:.6f})\")\n",
    "\n",
    "            try:\n",
    "                set_submodule_by_name(model, name, new_mod, device=device)\n",
    "            except KeyError as e:\n",
    "                print(\"WARNING: could not set submodule:\", name, e)\n",
    "\n",
    "        else:\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                print(f\"{name}: kept Conv2d FP32\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def dump_layer_dtypes(root: nn.Module, filter_prefix=None):\n",
    "    print(\"\\nLayer weight dtypes (first 200 layers):\")\n",
    "    for i, (name, m) in enumerate(root.named_modules()):\n",
    "        if i > 200:\n",
    "            break\n",
    "        if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "            w = getattr(m, \"weight\", None)\n",
    "            if w is not None:\n",
    "                print(f\"{name:40s} : weight dtype={w.dtype}  module_type={type(m).__name__}\")\n",
    "\n",
    "model_adaptive = deepcopy(model)\n",
    "model_adaptive.to(device)\n",
    "model_adaptive.eval()\n",
    "\n",
    "print(\"Collecting activation variance per layer...\")\n",
    "act_variances = compute_activation_variance(model_adaptive, test_loader, device)\n",
    "\n",
    "print(\"Applying adaptive FP32/FP16/INT8 quantization (fixed replacer)...\")\n",
    "model_adaptive = apply_adaptive_mixed_precision_fixed(\n",
    "    model_adaptive, act_variances, device=device, keep_conv_as_fp32=True)\n",
    "\n",
    "dump_layer_dtypes(model_adaptive)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model_adaptive(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "end_time = time.time()\n",
    "inf_time = end_time - start_time\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "model_size = get_model_size(model_adaptive, \"vgg11_adaptive_fp16_int8.pt\")\n",
    "\n",
    "print(f\"\\nAdaptive Mixed Precision (FP32/FP16/INT8): \"\n",
    "      f\"Accuracy = {test_acc:.2f}%, Inference Time = {inf_time:.2f}s, Size = {model_size:.2f} MB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
