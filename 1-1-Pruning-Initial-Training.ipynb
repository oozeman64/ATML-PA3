{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wucEItNRLSX"
      },
      "source": [
        "## VGG-11 Initial Training with CIFAR-100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8ytd9_JkRLSX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import random\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI3VcUKlRLSY",
        "outputId": "3a03b165-564c-4aa3-e6c8-b691b88d0914"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixed random seed: 42\n"
          ]
        }
      ],
      "source": [
        "def fix_random_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    print(f\"Fixed random seed: {seed}\")\n",
        "\n",
        "fix_random_seed(42)\n",
        "\n",
        "# For deterministic DataLoader behavior\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eK_7R3bKRLSY"
      },
      "outputs": [],
      "source": [
        "vgg11 = models.vgg11(weights=models.VGG11_Weights.IMAGENET1K_V1)\n",
        "vgg11.classifier[6] = torch.nn.Linear(4096, 100)\n",
        "vgg11.classifier[5] = torch.nn.Dropout(p=0.5) # Dropout\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
        "vgg11 = vgg11.to(device)\n",
        "\n",
        "base_lr = 0.04\n",
        "weight_decay = 5e-4\n",
        "num_epochs = 5\n",
        "optim = torch.optim.SGD(\n",
        "    vgg11.parameters(),\n",
        "    lr=base_lr,\n",
        "    momentum=0.9,\n",
        "    weight_decay=weight_decay\n",
        ")\n",
        "\n",
        "scheduler = CosineAnnealingLR(optim, T_max=num_epochs, eta_min=1e-5)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zcLuozcRLSY",
        "outputId": "3f84949e-e7bb-45ba-9efe-f8114ff39331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 47500\n",
            "Validation set size: 2500\n",
            "Test set size: 10000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std = [0.229, 0.224, 0.225]\n",
        "BATCH_SIZE = 128\n",
        "NUM_WORKERS = 4\n",
        "VAL_RATIO = 0.05\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(42)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
        "])\n",
        "\n",
        "def split_train_val(dataset, ratio=VAL_RATIO, generator=g):\n",
        "    total_size = len(dataset)\n",
        "    val_size = int(ratio * total_size)\n",
        "    train_size = total_size - val_size\n",
        "    return random_split(dataset, [train_size, val_size], generator=generator)\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data', train=True, download=True, transform=transform\n",
        ")\n",
        "\n",
        "train_dataset, val_dataset = split_train_val(train_dataset, VAL_RATIO, g)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data', train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "print(\"Training set size:\", len(train_dataset))\n",
        "print(\"Validation set size:\", len(val_dataset))\n",
        "print(\"Test set size:\", len(test_dataset))\n",
        "\n",
        "def get_loader(dataset, shuffle):\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g\n",
        "    )\n",
        "\n",
        "train_loader = get_loader(train_dataset, shuffle=True)\n",
        "val_loader = get_loader(val_dataset, shuffle=False)\n",
        "test_loader = get_loader(test_dataset, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DQCjNT5GRLSY"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for inputs, labels in loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / total\n",
        "    accuracy = 100. * correct / total\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rpqKtoZ7RLSZ"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            preds = model(images)\n",
        "            preds = torch.argmax(preds, dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OuWwFUrRLSZ",
        "outputId": "da219e2b-3e01-4846-d8b5-a9fe007a42ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 | Loss: 2.8078 | Train Acc: 29.81% | Val Acc: 34.60\n",
            "Epoch 2/5 | Loss: 1.8943 | Train Acc: 48.62% | Val Acc: 53.44\n",
            "Epoch 3/5 | Loss: 1.3754 | Train Acc: 61.03% | Val Acc: 57.56\n",
            "Epoch 4/5 | Loss: 0.9094 | Train Acc: 73.18% | Val Acc: 68.16\n",
            "Epoch 5/5 | Loss: 0.5731 | Train Acc: 82.23% | Val Acc: 72.28\n"
          ]
        }
      ],
      "source": [
        "best_val = 0\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train_epoch(vgg11, train_loader, criterion, optim, device)\n",
        "    scheduler.step()\n",
        "    val_acc = evaluate(vgg11, val_loader, device)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}\")\n",
        "    if val_acc > best_val:\n",
        "      best_val = val_acc\n",
        "      torch.save(vgg11.state_dict(), \"vgg11_cifar100_baseline.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P15NV9ImRLSZ",
        "outputId": "3daa3271-f550-443e-debb-5e9372676aca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 72.66%\n"
          ]
        }
      ],
      "source": [
        "acc = evaluate(vgg11, test_loader, device)\n",
        "print(f\"Accuracy: {acc:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
